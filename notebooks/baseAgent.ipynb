{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad253cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\case\\AI-hackaton-kemenkes\\agent\\ragagent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings \n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e4053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "if not os.getenv(\"GEMINI_API_KEY\") and not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"GEMINI_API_KEY atau GOOGLE_API_KEY tidak ditemukan di environment variables.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5240ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "LLM_MODEL = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4773bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, chunk_size: int = 1000, overlap: int = 200):\n",
    "        self.textSplitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "        )\n",
    "\n",
    "    def processText(self, text: str) -> list[Document]:\n",
    "        \"\"\" Memecah teks panjang menjadi chunks dan konversi ke objek Document \"\"\"\n",
    "        chunks = self.textSplitter.split_text(text)\n",
    "        return [Document(page_content=chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba43e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, embeddingFunction: GoogleGenerativeAIEmbeddings):\n",
    "        self.embeddingFunction = embeddingFunction\n",
    "        self.vectorStore = None\n",
    "    \n",
    "    def createIndex(self, documents: list[Document]):\n",
    "        \"\"\" Membuat indeks vector store menggunakan FAISS dengan wrapper LangChain \"\"\"\n",
    "\n",
    "        self.vectorStore = FAISS.from_documents(\n",
    "            documents=documents, \n",
    "            embedding=self.embeddingFunction\n",
    "        )\n",
    "        return self.vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480476b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, vectorStore: FAISS):\n",
    "        self.retriever = vectorStore.as_retriever(search_kwargs={\"k\": 5})\n",
    "    \n",
    "    def retrieve(self, query: str) -> list[Document]:\n",
    "        \"\"\" Melakukan pencarian pada vector store untuk menemukan data relevan \"\"\"\n",
    "\n",
    "        return self.retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11530da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotAgent:\n",
    "    def __init__(self, vectorStore: FAISS, llm_model: ChatGoogleGenerativeAI):\n",
    "        self.vectorStore = vectorStore\n",
    "        self.llm = llm_model\n",
    "        self.retriever = Retriever(vectorStore)\n",
    "    \n",
    "        # PROMPT RAG\n",
    "        self.promptTemplate = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                Anda adalah Asisten Pakar Gizi dan Pencegahan stunting untuk ibu hamil bernama MateBot panggil setiap user Bunda. Jawablah pertanyaan pengguna **HANYA** berdasarkan konteks yang diberikan di bawah.\n",
    "                Pastikan jawaban Anda:\n",
    "                1. Menggunakan bahasa Indonesia formal, ramah, dan informatif.\n",
    "                2. Menyebutkan **Definisi**, **Penyebab**, dan **Pencegahan** jika relevan.\n",
    "                3. Gunakan bullet point atau penomoran untuk memudahkan pembacaan.\n",
    "\n",
    "                KONTEKS:\n",
    "                {context}\n",
    "                \"\"\"),\n",
    "                (\"user\", \"{query}\")\n",
    "        ])\n",
    "\n",
    "        self.FALLBACK_PROMPT = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                Bunda bertanya tentang '{query}'. Informasi spesifik tidak ditemukan di basis data gizi MateBot.\n",
    "                Jawab pertanyaan ini menggunakan pengetahuan umum Anda HANYA JIKA topik tersebut masih berhubungan erat dengan Gizi, Kehamilan, atau Stunting. \n",
    "                Jika pertanyaan sama sekali tidak berhubungan dengan topik ini (misalnya, sejarah, geografi, atau politik), jawab: 'Maaf Bunda, saya hanya dilatih untuk memberikan informasi spesifik mengenai gizi dan pencegahan stunting.' \n",
    "                Berikan jawaban dengan memanggil user 'Bunda' dan berikan disclaimer bahwa ini adalah informasi umum.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "    \n",
    "    def generateResponse(self, query: str):\n",
    "        \"\"\" Menghasilkan respons menggunakan retriever dan model generatif (Gemini) \"\"\"\n",
    "        \n",
    "        DOC_COUNT = 5 \n",
    "        DISTANCE_THRESHOLD = 0.4 \n",
    "\n",
    "        scoredDocs = self.vectorStore.similarity_search_with_score(query, k=DOC_COUNT)\n",
    "        \n",
    "        bestDistance = scoredDocs[0][1] if scoredDocs else 999.0\n",
    "        \n",
    "        retrievedData = []\n",
    "        \n",
    "        if bestDistance > DISTANCE_THRESHOLD:\n",
    "            response = self.llm.invoke(self.FALLBACK_PROMPT.format(query=query))\n",
    "            retrievedData.append(Document(page_content=\"[SUMBER: Pengetahuan Umum MateBot (Tidak bersumber dari data gizi spesifik).]\", metadata={\"source\": \"Gemini Knowledge\"}))\n",
    "            \n",
    "        else:\n",
    "            retrievedData = self.retriever.retrieve(query)\n",
    "            context = \"\\n---\\n\".join([doc.page_content for doc in retrievedData])\n",
    "            \n",
    "            response = self.llm.invoke(\n",
    "                self.promptTemplate.format_messages(context=context, query=query)\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.content,\n",
    "            \"source_documents\": retrievedData\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5da99",
   "metadata": {},
   "source": [
    "### ==============================================================================\n",
    "### GLOBAL FUNCTIONS\n",
    "### =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5b8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processKnowledgeData(file_path: str = \"../data/giziData.json\"):\n",
    "    \"\"\" Alur kerja Indexing: Load, Split, Embed, Store \"\"\"\n",
    "    loader = JSONLoader(\n",
    "        file_path=file_path,\n",
    "        jq_schema='.[]', \n",
    "        text_content=False, \n",
    "        content_key=\"content\",\n",
    "        \n",
    "        metadata_func=lambda record: {\n",
    "            \"id\": record.get(\"id\", \"N/A\"),\n",
    "            \"topic\": record.get(\"topic\", \"N/A\"),\n",
    "            \"sub_topic\": record.get(\"sub_topic\", \"N/A\"),\n",
    "            \"source\": record.get(\"source\", \"N/A\"),\n",
    "            \"date_updated\": record.get(\"date_updated\", \"N/A\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    dataProcessor = DataProcessor() \n",
    "    documentsAfterSplit = dataProcessor.textSplitter.split_documents(documents)\n",
    "    \n",
    "    vectorDb = VectorDatabase(embeddingFunction=EMBEDDING_MODEL)\n",
    "    vectorStore = vectorDb.createIndex(documentsAfterSplit)\n",
    "    \n",
    "    vectorStore.save_local(folder_path=\"./gizi_vector_index\", index_name=\"gizi_index\")\n",
    "    \n",
    "    return vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b347fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Vector Store berhasil dimuat dari disk.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    EMBEDDING_MODEL_RUNTIME = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "    VECTOR_STORE_GLOBAL = FAISS.load_local(\n",
    "        folder_path=\"../data/gizi_vector_index\", \n",
    "        embeddings=EMBEDDING_MODEL_RUNTIME,\n",
    "        index_name=\"gizi_index\",\n",
    "        allow_dangerous_deserialization=True\n",
    "    )\n",
    "    print(\"✅ Vector Store berhasil dimuat dari disk.\")\n",
    "except:\n",
    "    print(\"⚠️ Vector Store tidak ditemukan, membuat indeks baru...\")\n",
    "    # VECTOR_STORE_GLOBAL = processKnowledgeData() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21b6a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFlow(query):\n",
    "    \"\"\" Fungsi utama untuk menjalankan RAG \"\"\"\n",
    "    # retriever = Retriever(VECTOR_STORE_GLOBAL) \n",
    "    chatbot = ChatbotAgent(\n",
    "        vectorStore=VECTOR_STORE_GLOBAL, \n",
    "        llm_model=LLM_MODEL\n",
    "    ) \n",
    "    response = chatbot.generateResponse(query) \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a02883e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Apa itu Stunting?\"\n",
    "response = mainFlow(query)\n",
    "\n",
    "print(\"--- Hasil Jawaban Chatbot ---\")\n",
    "print(response['answer'])\n",
    "\n",
    "print(\"\\n--- Dokumen Sumber yang Digunakan ---\")\n",
    "for doc in response['source_documents']:\n",
    "\n",
    "    print(f\"- {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66ca96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
