{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad253cbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\case\\AI-hackaton-kemenkes\\agent\\ragagent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI\n",
    "from langchain_core.documents import Document\n",
    "from langchain_community.document_loaders import JSONLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "import os\n",
    "import chromadb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e4053b",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "if not os.getenv(\"GEMINI_API_KEY\") and not os.getenv(\"GOOGLE_API_KEY\"):\n",
    "    raise ValueError(\"GEMINI_API_KEY atau GOOGLE_API_KEY tidak ditemukan di environment variables.\")\n",
    "\n",
    "chromaDB = os.getenv(\"CHROMA_DB_URL\")\n",
    "parsed_url = urlparse(chromaDB)\n",
    "host = parsed_url.hostname\n",
    "port = parsed_url.port\n",
    "\n",
    "client = chromadb.HttpClient(host=host, port=port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5240ec66",
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_MODEL = GoogleGenerativeAIEmbeddings(model=\"text-embedding-004\")\n",
    "LLM_MODEL = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\", temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4773bf72",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self, chunk_size: int = 1000, overlap: int = 200):\n",
    "        self.textSplitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=overlap,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
    "        )\n",
    "\n",
    "    def processText(self, text: str) -> list[Document]:\n",
    "        \"\"\" Memecah teks panjang menjadi chunks dan konversi ke objek Document \"\"\"\n",
    "        chunks = self.textSplitter.split_text(text)\n",
    "        return [Document(page_content=chunk) for chunk in chunks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eba43e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorDatabase:\n",
    "    def __init__(self, embeddingFunction : EMBEDDING_MODEL, vectorStore : Chroma, client : client):\n",
    "        self.embeddingFunction = embeddingFunction\n",
    "        self.vectorStore = vectorStore\n",
    "        self.client = client\n",
    "    \n",
    "    def createIndex(self, documents: list[Document]):\n",
    "        \"\"\" Membuat indeks vector store menggunakan FAISS dengan wrapper LangChain \"\"\"\n",
    "\n",
    "        self.vectorStore = self.vectorStore.get_or_create_collection(\"gizi_data\")\n",
    "\n",
    "        for doc in documents:\n",
    "            content = doc.page_content if hasattr(doc, 'page_content') else doc['content']\n",
    "\n",
    "            embedding = self.embeddingFunction.embed_documents([content])[0]\n",
    "            \n",
    "            self.vectorStore.add(\n",
    "                [embedding],  # \n",
    "                metadatas=[{\n",
    "                    \"id\": doc.get(\"id\", \"N/A\"),\n",
    "                    \"topic\": doc.get(\"topic\", \"N/A\"),\n",
    "                    \"sub_topic\": doc.get(\"sub_topic\", \"N/A\"),\n",
    "                    \"source\": doc.get(\"source\", \"N/A\"),\n",
    "                    \"date_updated\": doc.get(\"date_updated\", \"N/A\"),\n",
    "                }],\n",
    "                ids=[f\"doc_{doc['id']}\"]  \n",
    "            )\n",
    "            \n",
    "        return self.vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "480476b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Retriever:\n",
    "    def __init__(self, vectorStore : Chroma):\n",
    "        self.retriever = vectorStore.as_retriever(search_kwargs={\"k\": 5})\n",
    "        self.vectorStore = vectorStore\n",
    "    \n",
    "    def retrieve(self, query: str) -> list[Document]:\n",
    "        \"\"\" Melakukan pencarian pada vector store untuk menemukan data relevan \"\"\"\n",
    "        return self.retriever.invoke(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11530da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChatbotAgent:\n",
    "    def __init__(self, vectorStore, llm_model: ChatGoogleGenerativeAI):\n",
    "        self.vectorStore = vectorStore\n",
    "        self.llm = llm_model\n",
    "        self.retriever = Retriever(vectorStore)\n",
    "    \n",
    "        # PROMPT RAG\n",
    "        self.promptTemplate = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                Anda adalah Asisten Pakar Gizi dan Pencegahan stunting untuk ibu hamil bernama MateBot panggil setiap user Bunda. Jawablah pertanyaan pengguna **HANYA** berdasarkan konteks yang diberikan di bawah.\n",
    "                Pastikan jawaban Anda:\n",
    "                1. Menggunakan bahasa Indonesia formal, ramah, dan informatif.\n",
    "                2. Menyebutkan **Definisi**, **Penyebab**, dan **Pencegahan** jika relevan.\n",
    "                3. Gunakan bullet point atau penomoran untuk memudahkan pembacaan.\n",
    "\n",
    "                KONTEKS:\n",
    "                {context}\n",
    "                \"\"\"),\n",
    "                (\"user\", \"{query}\")\n",
    "        ])\n",
    "\n",
    "        self.FALLBACK_PROMPT = ChatPromptTemplate.from_messages([\n",
    "            (\"system\", \"\"\"\n",
    "                Bunda bertanya tentang '{query}'. Informasi spesifik tidak ditemukan di basis data gizi MateBot.\n",
    "                Jawab pertanyaan ini menggunakan pengetahuan umum Anda HANYA JIKA topik tersebut masih berhubungan erat dengan Gizi, Kehamilan, atau Stunting. \n",
    "                # Jika pertanyaan sama sekali tidak berhubungan dengan topik ini, jawab: 'Maaf Bunda, saya hanya dilatih untuk memberikan informasi spesifik mengenai gizi dan pencegahan stunting.' \n",
    "                Berikan jawaban dengan memanggil user 'Bunda' dan berikan disclaimer bahwa ini adalah informasi umum.\n",
    "            \"\"\"),\n",
    "            (\"user\", \"{query}\")\n",
    "        ])\n",
    "    \n",
    "    def generateResponse(self, query: str):\n",
    "        \"\"\" Menghasilkan respons menggunakan retriever dan model generatif (Gemini) \"\"\"\n",
    "        \n",
    "        DOC_COUNT = 5 \n",
    "        DISTANCE_THRESHOLD = 0.4 \n",
    "\n",
    "        scoredDocs = self.vectorStore.similarity_search_with_score(query, k=DOC_COUNT)\n",
    "        \n",
    "        bestDistance = scoredDocs[0][1] if scoredDocs else 999.0\n",
    "        \n",
    "        retrievedData = []\n",
    "        \n",
    "        if bestDistance > DISTANCE_THRESHOLD:\n",
    "            response = self.llm.invoke(self.FALLBACK_PROMPT.format(query=query))\n",
    "            retrievedData.append(Document(page_content=\"[SUMBER: Pengetahuan Umum MateBot (Tidak bersumber dari data gizi spesifik).]\", metadata={\"source\": \"Gemini Knowledge\"}))\n",
    "            \n",
    "        else:\n",
    "            retrievedData = self.retriever.retrieve(query)\n",
    "            context = \"\\n---\\n\".join([doc.page_content for doc in retrievedData])\n",
    "            \n",
    "            response = self.llm.invoke(\n",
    "                self.promptTemplate.format_messages(context=context, query=query)\n",
    "            )\n",
    "\n",
    "        return {\n",
    "            \"answer\": response.content,\n",
    "            \"source_documents\": retrievedData\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df5da99",
   "metadata": {},
   "source": [
    "### ==============================================================================\n",
    "### GLOBAL FUNCTIONS\n",
    "### =============================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b5b8394",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processKnowledgeData(file_path: str = \"../data/giziData.json\"):\n",
    "    \"\"\" Alur kerja Indexing: Load, Split, Embed, Store \"\"\"\n",
    "    loader = JSONLoader(\n",
    "        file_path=file_path,\n",
    "        jq_schema='.[]', \n",
    "        text_content=False, \n",
    "        content_key=\"content\",\n",
    "        \n",
    "        metadata_func=lambda record, metadata: {\n",
    "            \"id\": record.get(\"id\", \"N/A\"),\n",
    "            \"topic\": record.get(\"topic\", \"N/A\"),\n",
    "            \"sub_topic\": record.get(\"sub_topic\", \"N/A\"),\n",
    "            \"source\": record.get(\"source\", \"N/A\"),\n",
    "            \"date_updated\": record.get(\"date_updated\", \"N/A\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "    documents = loader.load()\n",
    "\n",
    "    dataProcessor = DataProcessor() \n",
    "    documentsAfterSplit = dataProcessor.textSplitter.split_documents(documents)\n",
    "\n",
    "    \n",
    "    vectorStore = Chroma.from_documents(\n",
    "        documents=documentsAfterSplit, \n",
    "        embedding=EMBEDDING_MODEL, \n",
    "        client=client,\n",
    "        collection_name=\"gizi_data\"\n",
    "    )\n",
    "    \n",
    "    return vectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b347fdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<chromadb.api.client.Client object at 0x00000204E1712420>\n",
      "✅ Vector Store berhasil dimuat dari Chroma DB.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aafau\\AppData\\Local\\Temp\\ipykernel_26456\\2868910057.py:4: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  VECTOR_STORE_GLOBAL = Chroma(\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    collection_native = client.get_collection(\"gizi_data\")\n",
    "    print(client)\n",
    "    VECTOR_STORE_GLOBAL = Chroma(\n",
    "        client=client,\n",
    "        collection_name=\"gizi_data\",\n",
    "        embedding_function=EMBEDDING_MODEL \n",
    "    )\n",
    "    print(\"✅ Vector Store berhasil dimuat dari Chroma DB.\")\n",
    "except:\n",
    "    print(\"⚠️ Vector Store tidak ditemukan di Chroma DB, membuat indeks baru...\")\n",
    "    VECTOR_STORE_GLOBAL = processKnowledgeData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b6a3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mainFlow(query):\n",
    "    \"\"\" Fungsi utama untuk menjalankan RAG \"\"\"\n",
    "    chatbot = ChatbotAgent(\n",
    "        vectorStore=VECTOR_STORE_GLOBAL, \n",
    "        llm_model=LLM_MODEL\n",
    "    ) \n",
    "    response = chatbot.generateResponse(query) \n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a02883e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Hasil Jawaban Chatbot ---\n",
      "Halo, Bunda! Saya MateBot, siap membantu Bunda.\n",
      "\n",
      "Bunda bertanya mengenai apa itu stunting. Berdasarkan informasi yang ada, berikut adalah **Definisi** stunting:\n",
      "\n",
      "*   Stunting adalah gangguan pertumbuhan dan perkembangan anak balita (di bawah lima tahun) yang ditandai dengan tinggi badan lebih rendah dari standar usianya.\n",
      "*   Kondisi ini disebabkan oleh kekurangan gizi kronis dan infeksi berulang, terutama selama periode 1.000 Hari Pertama Kehidupan (HPK).\n",
      "*   Dampak stunting tidak hanya membuat anak pendek, tetapi juga dapat menghambat perkembangan kognitif, meningkatkan risiko penyakit, dan menurunkan produktivitas di masa depan.\n",
      "\n",
      "--- Dokumen Sumber yang Digunakan ---\n",
      "- Penyebab stunting dari segi gizi meliputi: Kekurangan kalori yang menghambat pertumbuhan fisik; Kekurangan protein yang menyebabkan keterlambatan perk...\n",
      "- Penyebab stunting dari segi gizi meliputi: Kekurangan kalori yang menghambat pertumbuhan fisik; Kekurangan protein yang menyebabkan keterlambatan perk...\n",
      "- Penyebab stunting dari segi gizi meliputi: Kekurangan kalori yang menghambat pertumbuhan fisik; Kekurangan protein yang menyebabkan keterlambatan perk...\n",
      "- Penyebab stunting dari segi gizi meliputi: Kekurangan kalori yang menghambat pertumbuhan fisik; Kekurangan protein yang menyebabkan keterlambatan perk...\n",
      "- Stunting adalah gangguan pertumbuhan dan perkembangan anak balita (di bawah lima tahun) yang ditandai dengan tinggi badan lebih rendah dari standar us...\n"
     ]
    }
   ],
   "source": [
    "query = \"Apa itu stunting\"\n",
    "response = mainFlow(query)\n",
    "\n",
    "print(\"--- Hasil Jawaban Chatbot ---\")\n",
    "print(response['answer'])\n",
    "\n",
    "print(\"\\n--- Dokumen Sumber yang Digunakan ---\")\n",
    "for doc in response['source_documents']:\n",
    "\n",
    "    print(f\"- {doc.page_content[:150]}...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a66ca96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragagent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
